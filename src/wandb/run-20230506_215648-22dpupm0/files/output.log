/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn("Default upsampling behavior when mode={} is changed "









Validating: 100% 160/160 [02:45<00:00,  1.10s/it][ 0.  0. nan nan  0.  0.  0.  0.]
/gdrive/MyDrive/TransSeg/src/utils.py:317: RuntimeWarning: invalid value encountered in true_divide
  acc = total_area_intersect / total_area_label
/gdrive/MyDrive/TransSeg/src/utils.py:321: RuntimeWarning: invalid value encountered in true_divide
  iou = total_area_intersect / total_area_union
/gdrive/MyDrive/TransSeg/src/utils.py:324: RuntimeWarning: invalid value encountered in true_divide
  dice = 2 * total_area_intersect / (total_area_pred_label + total_area_label)
/usr/local/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
Global seed set to 1234
Loading dataset:   2% 1/64 [00:00<00:12,  4.94it/s]
--------------------------------------------------------------------------------
DATALOADER:0 VALIDATE RESULTS
{'val/acc': 0.9939689040184021,
 'val/ce_loss': 0.0,
 'val/dice_loss': 0.0,
 'val/loss': 0.9318637847900391,
 'val/macc': nan,
 'val/mdice': nan,
 'val/mdice_8': nan,
 'val/mdice_nobg': nan,
 'val/miou': nan}
--------------------------------------------------------------------------------
GB: END trainer.validate(datamodule=dm)
GB: START trainer.test(datamodule=dm)
Loading dataset: 100% 64/64 [00:01<00:00, 41.20it/s]
Loading dataset: 100% 64/64 [00:02<00:00, 27.23it/s]
Loading dataset: 100% 64/64 [00:02<00:00, 25.72it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
# Train: 1831, # Val: 320, # Test: 120...
Testing: 0it [00:00, ?it/s]
Traceback (most recent call last):
  File "main.py", line 180, in <module>
    evaluate(args)
  File "main.py", line 171, in evaluate
    trainer.test(model, datamodule=dm)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 705, in test
    results = self._run(model)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 922, in _run
    self._dispatch()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_evaluating(self)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 95, in start_evaluating
    self.training_type_plugin.start_evaluating(trainer)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 165, in start_evaluating
    self._results = trainer.run_stage()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 997, in run_stage
    return self._run_evaluate()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1083, in _run_evaluate
    eval_loop_results = self._evaluation_loop.run()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 111, in advance
    output = self.evaluation_step(batch, batch_idx, dataloader_idx)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 154, in evaluation_step
    output = self.trainer.accelerator.test_step(step_kwargs)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 226, in test_step
    return self.training_type_plugin.test_step(*step_kwargs.values())
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py", line 395, in test_step
    return self.model(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 619, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/overrides/base.py", line 91, in forward
    output = self.module.test_step(*inputs, **kwargs)
  File "/gdrive/MyDrive/TransSeg/src/model.py", line 328, in test_step
    loss, (dice_loss, ce_loss) = self.criterion(outputs, labels)
  File "/usr/local/lib/python3.8/site-packages/torch/tensor.py", line 588, in __iter__
    raise TypeError('iteration over a 0-d tensor')
TypeError: iteration over a 0-d tensor