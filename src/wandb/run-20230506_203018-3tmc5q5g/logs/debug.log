2023-05-06 20:30:18,879 INFO    MainThread:50486 [wandb_setup.py:_flush():69] setting env: {}
2023-05-06 20:30:18,880 INFO    MainThread:50486 [wandb_setup.py:_flush():69] setting login settings: {}
2023-05-06 20:30:18,880 INFO    MainThread:50486 [wandb_init.py:_log_setup():357] Logging user logs to /gdrive/MyDrive/TransSeg/src/wandb/run-20230506_203018-3tmc5q5g/logs/debug.log
2023-05-06 20:30:18,881 INFO    MainThread:50486 [wandb_init.py:_log_setup():358] Logging internal logs to /gdrive/MyDrive/TransSeg/src/wandb/run-20230506_203018-3tmc5q5g/logs/debug-internal.log
2023-05-06 20:30:18,881 INFO    MainThread:50486 [wandb_init.py:init():390] calling init triggers
2023-05-06 20:30:18,881 INFO    MainThread:50486 [wandb_init.py:init():395] wandb.init called with sweep_config: {}
config: {'data_dir': 'data/bcv/processed/', 'split_json': 'dataset_5slices.json', 'train_batch_size': 2, 'eval_batch_size': 2, 'clip_range': [-175, 250], 'mean_std': None, 'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 14, 'patch_size': 16, 'img_size': [512, 512, 5], 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'default_root_dir': '.', 'gpus': -1, 'val_check_interval': 1.0, 'check_val_every_n_epoch': 100, 'gradient_clip_val': 1.0, 'accumulate_grad_batches': 1, 'log_every_n_steps': 1, 'precision': 32, 'accelerator': 'ddp', 'seed': 1234, 'evaluation': 1, 'model_path': 'data/bcv/processed/checkpoint/ours/inflation/epoch=13-step=15469.ckpt', 'checkpoint_dir': 'checkpoints'}
2023-05-06 20:30:18,881 INFO    MainThread:50486 [wandb_init.py:init():435] starting backend
2023-05-06 20:30:18,881 INFO    MainThread:50486 [backend.py:_multiprocessing_setup():70] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-05-06 20:30:18,951 INFO    MainThread:50486 [backend.py:ensure_launched():135] starting backend process...
2023-05-06 20:30:19,019 INFO    MainThread:50486 [backend.py:ensure_launched():139] started backend process with pid: 50756
2023-05-06 20:30:19,021 INFO    MainThread:50486 [wandb_init.py:init():440] backend started and connected
2023-05-06 20:30:19,025 INFO    MainThread:50486 [wandb_init.py:init():499] updated telemetry
2023-05-06 20:30:19,025 INFO    MainThread:50486 [wandb_init.py:init():522] communicating current version
2023-05-06 20:30:20,037 INFO    MainThread:50486 [wandb_init.py:init():527] got version response upgrade_message: "wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-05-06 20:30:20,037 INFO    MainThread:50486 [wandb_init.py:init():535] communicating run to backend with 30 second timeout
2023-05-06 20:30:20,649 INFO    MainThread:50486 [wandb_init.py:init():562] starting run threads in backend
2023-05-06 20:30:25,656 INFO    MainThread:50486 [wandb_run.py:_console_start():1651] atexit reg
2023-05-06 20:30:25,660 INFO    MainThread:50486 [wandb_run.py:_redirect():1525] redirect: SettingsConsole.REDIRECT
2023-05-06 20:30:25,661 INFO    MainThread:50486 [wandb_run.py:_redirect():1530] Redirecting console.
2023-05-06 20:30:25,662 INFO    MainThread:50486 [wandb_run.py:_redirect():1586] Redirects installed.
2023-05-06 20:30:25,663 INFO    MainThread:50486 [wandb_init.py:init():587] run started, returning control to user process
2023-05-06 20:30:25,663 INFO    MainThread:50486 [wandb_run.py:_config_callback():878] config_cb None None {'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'inflation', 'in_channels': 1, 'out_channels': 14, 'patch_size': 16, 'img_size': [512, 512, 5], 'hidden_size': 768, 'mlp_dim': 3072, 'num_heads': 12, 'num_layers': 12, 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'save_preds': False, 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'adam_epsilon': 1e-08}
2023-05-06 20:39:08,850 INFO    MainThread:50486 [wandb_run.py:_config_callback():878] config_cb None None {'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'inflation', 'in_channels': 1, 'out_channels': 14, 'patch_size': 16, 'img_size': [512, 512, 5], 'hidden_size': 768, 'mlp_dim': 3072, 'num_heads': 12, 'num_layers': 12, 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'save_preds': False, 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'adam_epsilon': 1e-08}
2023-05-06 20:39:08,853 INFO    MainThread:50486 [wandb_run.py:_atexit_cleanup():1621] got exitcode: 1
2023-05-06 20:39:08,853 INFO    MainThread:50486 [wandb_run.py:_restore():1593] restore
2023-05-06 20:39:10,906 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 1298
  total_bytes: 1298
}

2023-05-06 20:39:11,014 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 1298
  total_bytes: 1298
}

2023-05-06 20:39:11,431 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 1298
  total_bytes: 1298
}

2023-05-06 20:39:12,033 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 1298
  total_bytes: 19911
}

2023-05-06 20:39:12,135 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 1298
  total_bytes: 19911
}

2023-05-06 20:39:12,237 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 1298
  total_bytes: 19911
}

2023-05-06 20:39:12,339 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:12,442 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:12,544 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:12,647 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:12,749 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:12,851 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:12,954 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:13,056 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:13,633 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}

2023-05-06 20:39:14,269 INFO    MainThread:50486 [wandb_run.py:_wait_for_finish():1746] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19911
  total_bytes: 19911
}
local_info {
}

2023-05-06 20:39:15,552 INFO    MainThread:50486 [wandb_run.py:_append_history():1959] rendering history
2023-05-06 20:39:15,553 INFO    MainThread:50486 [wandb_run.py:_append_summary():1914] rendering summary
2023-05-06 20:39:15,553 INFO    MainThread:50486 [wandb_run.py:_append_files():2009] logging synced files
