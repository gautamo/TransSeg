
Validating:   0% 0/784 [00:00<?, ?it/s]
/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.








































Validating: 100% 784/784 [08:05<00:00,  1.62it/s][0.85343656 0.53743243 0.86053601 0.87466171 0.94998138 0.67116763
 0.86918966 0.77697029]
--------------------------------------------------------------------------------
DATALOADER:0 VALIDATE RESULTS
{'val/acc': 0.9913884401321411,
 'val/ce_loss': 0.0,
 'val/dice_loss': 0.0,
 'val/loss': 0.753157913684845,
 'val/macc': 0.7942692637443542,
 'val/mdice': 0.7515371441841125,
 'val/mdice_8': 0.7991719841957092,
 'val/mdice_nobg': 0.7327187657356262,
 'val/miou': 0.6284027099609375}
--------------------------------------------------------------------------------
/usr/local/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.
  rank_zero_deprecation(
Global seed set to 1234
Loading dataset:   2% 1/64 [00:00<00:07,  8.89it/s]
GB: END trainer.validate(datamodule=dm)
GB: START trainer.test(datamodule=dm)




Loading dataset: 100% 64/64 [00:08<00:00,  7.56it/s]




Loading dataset:  80% 51/64 [00:09<00:02,  5.96it/s]
Loading dataset: 100% 64/64 [00:10<00:00,  5.99it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Traceback (most recent call last):
  File "main.py", line 180, in <module>
    evaluate(args)
  File "main.py", line 171, in evaluate
    trainer.test(model, datamodule=dm)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 705, in test
    results = self._run(model)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 922, in _run
    self._dispatch()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_evaluating(self)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 95, in start_evaluating
    self.training_type_plugin.start_evaluating(trainer)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 165, in start_evaluating
    self._results = trainer.run_stage()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 997, in run_stage
    return self._run_evaluate()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1077, in _run_evaluate
    self._evaluation_loop.reload_evaluation_dataloaders()
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 170, in reload_evaluation_dataloaders
    self.trainer.reset_test_dataloader(model)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py", line 452, in reset_test_dataloader
    self.num_test_batches, self.test_dataloaders = self._reset_eval_dataloader(model, "test")
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py", line 402, in _reset_eval_dataloader
    num_batches = len(dataloader) if has_len(dataloader) else float("inf")
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py", line 63, in has_len
    raise ValueError("`Dataloader` returned 0 length. Please make sure that it returns at least 1 batch")
ValueError: `Dataloader` returned 0 length. Please make sure that it returns at least 1 batch