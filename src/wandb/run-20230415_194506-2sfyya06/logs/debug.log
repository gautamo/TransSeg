2023-04-15 19:45:06,528 INFO    MainThread:35676 [wandb_setup.py:_flush():69] setting env: {}
2023-04-15 19:45:06,529 INFO    MainThread:35676 [wandb_setup.py:_flush():69] setting login settings: {}
2023-04-15 19:45:06,529 INFO    MainThread:35676 [wandb_setup.py:_flush():69] setting login settings: {'api_key': 'c938c0a5d0f96ef063e9a27072521b6fb39c2015'}
2023-04-15 19:45:06,530 INFO    MainThread:35676 [wandb_init.py:_log_setup():357] Logging user logs to /gdrive/MyDrive/TransSeg/src/wandb/run-20230415_194506-2sfyya06/logs/debug.log
2023-04-15 19:45:06,530 INFO    MainThread:35676 [wandb_init.py:_log_setup():358] Logging internal logs to /gdrive/MyDrive/TransSeg/src/wandb/run-20230415_194506-2sfyya06/logs/debug-internal.log
2023-04-15 19:45:06,530 INFO    MainThread:35676 [wandb_init.py:init():390] calling init triggers
2023-04-15 19:45:06,531 INFO    MainThread:35676 [wandb_init.py:init():395] wandb.init called with sweep_config: {}
config: {'data_dir': 'data/msd/processed/Task09_Spleen/', 'split_json': 'dataset_5slices.json', 'train_batch_size': 2, 'eval_batch_size': 2, 'clip_range': [-175, 250], 'mean_std': None, 'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 2, 'patch_size': 16, 'img_size': [512, 512, 5], 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'default_root_dir': '.', 'gpus': -1, 'val_check_interval': 1.0, 'check_val_every_n_epoch': 100, 'gradient_clip_val': 1.0, 'accumulate_grad_batches': 2, 'log_every_n_steps': 1, 'precision': 32, 'accelerator': 'ddp', 'seed': 1234, 'evaluation': 0, 'model_path': None}
2023-04-15 19:45:06,531 INFO    MainThread:35676 [wandb_init.py:init():435] starting backend
2023-04-15 19:45:06,531 INFO    MainThread:35676 [backend.py:_multiprocessing_setup():70] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-04-15 19:45:06,622 INFO    MainThread:35676 [backend.py:ensure_launched():135] starting backend process...
2023-04-15 19:45:06,714 INFO    MainThread:35676 [backend.py:ensure_launched():139] started backend process with pid: 36088
2023-04-15 19:45:06,718 INFO    MainThread:35676 [wandb_init.py:init():440] backend started and connected
2023-04-15 19:45:06,722 INFO    MainThread:35676 [wandb_init.py:init():499] updated telemetry
2023-04-15 19:45:06,723 INFO    MainThread:35676 [wandb_init.py:init():522] communicating current version
2023-04-15 19:45:07,775 INFO    MainThread:35676 [wandb_init.py:init():527] got version response upgrade_message: "wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-04-15 19:45:07,776 INFO    MainThread:35676 [wandb_init.py:init():535] communicating run to backend with 30 second timeout
2023-04-15 19:45:09,498 INFO    MainThread:35676 [wandb_init.py:init():562] starting run threads in backend
2023-04-15 19:45:14,507 INFO    MainThread:35676 [wandb_run.py:_console_start():1651] atexit reg
2023-04-15 19:45:14,510 INFO    MainThread:35676 [wandb_run.py:_redirect():1525] redirect: SettingsConsole.REDIRECT
2023-04-15 19:45:14,511 INFO    MainThread:35676 [wandb_run.py:_redirect():1530] Redirecting console.
2023-04-15 19:45:14,514 INFO    MainThread:35676 [wandb_run.py:_redirect():1586] Redirects installed.
2023-04-15 19:45:14,514 INFO    MainThread:35676 [wandb_init.py:init():587] run started, returning control to user process
2023-04-15 19:45:14,515 INFO    MainThread:35676 [wandb_run.py:_config_callback():878] config_cb None None {'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 2, 'patch_size': 16, 'img_size': [512, 512, 5], 'hidden_size': 768, 'mlp_dim': 3072, 'num_heads': 12, 'num_layers': 12, 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'save_preds': False, 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'adam_epsilon': 1e-08}
2023-04-16 01:38:13,884 INFO    MainThread:35676 [wandb_run.py:_config_callback():878] config_cb None None {'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 2, 'patch_size': 16, 'img_size': [512, 512, 5], 'hidden_size': 768, 'mlp_dim': 3072, 'num_heads': 12, 'num_layers': 12, 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'save_preds': False, 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'adam_epsilon': 1e-08}
2023-04-16 01:39:00,228 INFO    MainThread:35676 [wandb_run.py:_atexit_cleanup():1621] got exitcode: 255
2023-04-16 01:39:00,228 INFO    MainThread:35676 [wandb_run.py:_restore():1593] restore
2023-04-16 01:39:07,927 INFO    MainThread:35676 [wandb_run.py:_wait_for_finish():1746] got exit ret: None
2023-04-16 01:39:08,028 INFO    MainThread:35676 [wandb_run.py:_restore():1593] restore
