2023-04-16 16:35:55,240 INFO    MainThread:50255 [wandb_setup.py:_flush():69] setting env: {}
2023-04-16 16:35:55,241 INFO    MainThread:50255 [wandb_setup.py:_flush():69] setting login settings: {}
2023-04-16 16:35:55,242 INFO    MainThread:50255 [wandb_init.py:_log_setup():357] Logging user logs to /gdrive/MyDrive/TransSeg/src/wandb/run-20230416_163555-33ddr0lf/logs/debug.log
2023-04-16 16:35:55,242 INFO    MainThread:50255 [wandb_init.py:_log_setup():358] Logging internal logs to /gdrive/MyDrive/TransSeg/src/wandb/run-20230416_163555-33ddr0lf/logs/debug-internal.log
2023-04-16 16:35:55,243 INFO    MainThread:50255 [wandb_init.py:init():390] calling init triggers
2023-04-16 16:35:55,243 INFO    MainThread:50255 [wandb_init.py:init():395] wandb.init called with sweep_config: {}
config: {'data_dir': 'data/bcv/processed/', 'split_json': 'dataset_5slices.json', 'train_batch_size': 2, 'eval_batch_size': 2, 'clip_range': [-175, 250], 'mean_std': None, 'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 14, 'patch_size': 16, 'img_size': [512, 512, 5], 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 25000, 'default_root_dir': '.', 'gpus': -1, 'val_check_interval': 1.0, 'check_val_every_n_epoch': 100, 'gradient_clip_val': 1.0, 'accumulate_grad_batches': 1, 'log_every_n_steps': 1, 'precision': 32, 'accelerator': 'ddp', 'seed': 1234, 'evaluation': 1, 'model_path': 'data/bcv/processed/checkpoint/ours/ours.pt', 'checkpoint_dir': 'checkpoints'}
2023-04-16 16:35:55,243 INFO    MainThread:50255 [wandb_init.py:init():435] starting backend
2023-04-16 16:35:55,244 INFO    MainThread:50255 [backend.py:_multiprocessing_setup():70] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-04-16 16:35:55,326 INFO    MainThread:50255 [backend.py:ensure_launched():135] starting backend process...
2023-04-16 16:35:55,412 INFO    MainThread:50255 [backend.py:ensure_launched():139] started backend process with pid: 50393
2023-04-16 16:35:55,415 INFO    MainThread:50255 [wandb_init.py:init():440] backend started and connected
2023-04-16 16:35:55,421 INFO    MainThread:50255 [wandb_init.py:init():499] updated telemetry
2023-04-16 16:35:55,422 INFO    MainThread:50255 [wandb_init.py:init():522] communicating current version
2023-04-16 16:35:56,491 INFO    MainThread:50255 [wandb_init.py:init():527] got version response upgrade_message: "wandb version 0.14.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-04-16 16:35:56,492 INFO    MainThread:50255 [wandb_init.py:init():535] communicating run to backend with 30 second timeout
2023-04-16 16:35:56,977 INFO    MainThread:50255 [wandb_init.py:init():562] starting run threads in backend
2023-04-16 16:36:01,986 INFO    MainThread:50255 [wandb_run.py:_console_start():1651] atexit reg
2023-04-16 16:36:01,991 INFO    MainThread:50255 [wandb_run.py:_redirect():1525] redirect: SettingsConsole.REDIRECT
2023-04-16 16:36:01,992 INFO    MainThread:50255 [wandb_run.py:_redirect():1530] Redirecting console.
2023-04-16 16:36:01,994 INFO    MainThread:50255 [wandb_run.py:_redirect():1586] Redirects installed.
2023-04-16 16:36:01,994 INFO    MainThread:50255 [wandb_init.py:init():587] run started, returning control to user process
2023-04-16 16:36:01,995 INFO    MainThread:50255 [wandb_run.py:_config_callback():878] config_cb None None {'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 14, 'patch_size': 16, 'img_size': [512, 512, 5], 'hidden_size': 768, 'mlp_dim': 3072, 'num_heads': 12, 'num_layers': 12, 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'save_preds': False, 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 5000, 'adam_epsilon': 1e-08}
2023-04-16 16:44:51,642 INFO    MainThread:50255 [wandb_run.py:_config_callback():878] config_cb None None {'force_2d': 0, 'use_pretrained': 1, 'bootstrap_method': 'centering', 'in_channels': 1, 'out_channels': 14, 'patch_size': 16, 'img_size': [512, 512, 5], 'hidden_size': 768, 'mlp_dim': 3072, 'num_heads': 12, 'num_layers': 12, 'encoder': 'beit', 'decoder': 'upernet', 'loss_type': 'dicefocal', 'save_preds': False, 'dropout_rate': 0.0, 'learning_rate': 3e-05, 'weight_decay': 0.05, 'warmup_steps': 20, 'max_steps': 5000, 'adam_epsilon': 1e-08}
2023-04-16 16:44:51,656 INFO    MainThread:50255 [wandb_run.py:_atexit_cleanup():1621] got exitcode: 1
2023-04-16 16:44:51,656 INFO    MainThread:50255 [wandb_run.py:_restore():1593] restore
2023-04-16 16:44:54,102 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 1271
  total_bytes: 1271
}

2023-04-16 16:44:54,515 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 1271
  total_bytes: 1271
}

2023-04-16 16:44:55,038 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 1271
  total_bytes: 16043
}

2023-04-16 16:44:55,141 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 1271
  total_bytes: 19846
}

2023-04-16 16:44:55,244 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 1271
  total_bytes: 19846
}

2023-04-16 16:44:55,347 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:55,449 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:55,552 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:55,655 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:55,757 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:55,860 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:55,962 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:56,417 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}

2023-04-16 16:44:56,891 INFO    MainThread:50255 [wandb_run.py:_wait_for_finish():1746] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 19846
  total_bytes: 19846
}
local_info {
}

2023-04-16 16:44:58,258 INFO    MainThread:50255 [wandb_run.py:_append_history():1959] rendering history
2023-04-16 16:44:58,259 INFO    MainThread:50255 [wandb_run.py:_append_summary():1914] rendering summary
2023-04-16 16:44:58,259 INFO    MainThread:50255 [wandb_run.py:_append_files():2009] logging synced files
