
Validation sanity check:   0% 0/2 [00:00<?, ?it/s]
  | Name      | Type          | Params
--------------------------------------------
0 | encoder   | BEiT3D        | 86.6 M
1 | decoder   | UPerHead      | 74.9 M
2 | criterion | DiceFocalLoss | 0
--------------------------------------------
161 M     Trainable params
0         Non-trainable params
161 M     Total params
646.207   Total estimated model params size (MB)
/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.

Epoch 0:   0% 0/1728 [00:00<00:00, 5210.32it/s]
/gdrive/MyDrive/TransSeg/src/utils.py:317: RuntimeWarning: invalid value encountered in true_divide
  acc = total_area_intersect / total_area_label








































































Epoch 0:  84% 1460/1728 [42:17<07:45,  1.74s/it, loss=0.453, v_num=f1lk]














Validating: 100% 271/271 [02:51<00:00,  1.60it/s]
/usr/local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.


































Epoch 1:  36% 620/1728 [18:12<32:29,  1.76s/it, loss=0.418, v_num=f1lk]
/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
Traceback (most recent call last):
  File "main.py", line 164, in <module>
    train(args)
  File "main.py", line 122, in train
    trainer.validate(datamodule=dm)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 624, in validate
    self.validated_ckpt_path = self.__load_ckpt_weights(ckpt_path)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1168, in __load_ckpt_weights
    self.checkpoint_connector.restore_model_weights(ckpt_path)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 148, in restore_model_weights
    checkpoint = self.trainer.training_type_plugin.load_checkpoint_file(checkpoint_path)
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 149, in load_checkpoint_file
    return pl_load(checkpoint_path, map_location=(lambda storage, loc: storage))
  File "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py", line 33, in load
    return torch.load(f, map_location=map_location)
  File "/usr/local/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/usr/local/lib/python3.8/site-packages/torch/serialization.py", line 853, in _load
    result = unpickler.load()
  File "/usr/local/lib/python3.8/site-packages/torch/serialization.py", line 845, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File "/usr/local/lib/python3.8/site-packages/torch/serialization.py", line 833, in load_tensor
    storage = zip_file.get_storage_from_record(name, size, dtype).storage()
KeyboardInterrupt